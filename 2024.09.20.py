# %%

import numpy as np
import pandas as pd
from scipy.optimize import shgo

# data_path = '/home/hoke/Downloads/gaze_pattern.csv'
data_path = '/home/hoke/Downloads/merged_behavioral.csv'


# %%
# 0-depth inference

def normalize(arr, axis=None):
    return np.divide(arr, np.sum(arr, axis=axis, keepdims=True))

def expectation(arr, pp, axis=None):
    return np.sum(np.multiply(arr, pp), axis=axis, keepdims=True)

def bayes(pp_y_given_x, pp_x, axis):
    '''axis = ax_x'''
    return normalize(np.multiply(pp_y_given_x, pp_x), axis=axis)

def average_bayes(pp_s_given_x, pp_x_given_c, pp_c, ax_c=0, ax_x=1, ax_s=2):
    '''inference on signals s, marginalized over s'''
    # inference on s
    pp_s_given_c = expectation(pp_s_given_x, pp_x_given_c, axis=ax_x)
    pp_c_given_s = bayes(pp_s_given_c, pp_c, axis=ax_c)
    # average beliefs about c
    pp_c_given_x = expectation(pp_c_given_s, pp_s_given_x, axis=ax_s)
    return pp_c_given_x

def pp_s_given_x_free(e_CT, e_CA, e_SA, e_ST):
    '''free parametrizations of signal structure'''
    tmp = np.array([[1 - e_CT, e_CT / 3, e_CT / 3, e_CT / 3],
                    [e_CA / 3, 1 - e_CA, e_CA / 3, e_CA / 3],
                    [e_SA / 3, e_SA / 3, 1 - e_SA, e_SA / 3],
                    [e_ST / 3, e_ST / 3, e_ST / 3, 1 - e_ST]])
    return np.expand_dims(tmp, axis=0)

def pp_s_given_x_symm(e_T, e_A):
    '''symmetric parametrizations of signal structure'''
    return pp_s_given_x_free(e_T, e_A, e_A, e_T)


ax_c, ax_x, ax_s = 0, 1, 2
n_c, n_x, n_s = 2, 4, 4

pp_c = normalize(np.ones((n_c, 1, 1)), axis=ax_c)
pp_x_given_c = normalize(np.array([[1, 1, 0, 0], [0, 0, 1, 1]])[:, :, np.newaxis], axis=ax_x)

# signal structure
pp_s_given_x = pp_s_given_x_free(*(1e-1 * np.random.random(4)))

# average inference
pp_c_given_x = average_bayes(pp_s_given_x, pp_x_given_c, pp_c)

print(pp_s_given_x)
print(pp_c_given_x)


# %%
# max-likelihood

df = pd.read_csv(data_path)
acc = np.array(df['ACC'])
df['i_c'] = (df['GameTask'] == 'Shape').astype(int)
df['i_t'] = (df['CueTransparency'] == 'Arbitrary').astype(int)
df['i_x'] = 3 * df['i_c'] + ( 1 - 2 * df['i_c'] ) * df['i_t']   # to achieve ordering (CT, CA, SA, ST)
df = df[['Subject', 'i_c', 'i_x', 'ACC']]

subject = 3
df = df[df['Subject'] == subject]
print(df.head())

ii_c, ii_x, acc = df['i_c'], df['i_x'], df['ACC']

def likelihood(pp_s_given_x, i_c, i_x, acc):
    '''
    i_c: index of context   (C, S)
    i_x: index of cue       (CT, CA, SA, ST)'''
    pp_c_given_x = average_bayes(pp_s_given_x, pp_x_given_c, pp_c)
    p = pp_c_given_x[i_c, i_x, 0]
    return acc * p + ( 1 - acc ) * ( 1 - p )

to_minimize = lambda args, pp_s_given_x_: -1 * np.sum(np.log(likelihood(pp_s_given_x_(*args), ii_c, ii_x, acc)))

eps = 1e-2

n_params = 4
res_free = shgo(to_minimize, bounds=(n_params * [(eps, 1/2)]), args=(pp_s_given_x_free,))
print(res_free)

n_params = 2
res_symm = shgo(to_minimize, bounds=(n_params * [(eps, 1/2)]), args=(pp_s_given_x_symm,))
print(res_symm)



# %%
# regression of reaction times on changes in trial type
import pandas as pd
import sklearn as sk
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression


def extract_basic_features(row):
    f1 = -1 if str(row["Target"])[:5] == "Green" else 1
    f2 = -1 if str(row["Target"])[-3:] == "Car" else 1
    f3 = -1 if row["CueTransparency"] == "Transparent" else 1
    f4 = -1 if row["GameTask"] == "Colour" else 1
    f = [f1, f2, f3, f4]
    return f


def extract_gaze_type(row):
    key = {"TargetOnly": [1, 0, 0, 0],
           "CueOnly": [0, 1, 0, 0],
           "TargetCue": [0, 0, 1, 0],
           "CueTarget": [0, 0, 0, 1]}
    return key[row["GazePattern"]]


def extract_demographic(row, maxage):
    gender = -1 if row["Sex"] == "male" else 1
    age = row["Age"] / maxage
    return [gender, age]


def setup_data(data):
    y = data["RT"].to_list()
    x = []
    maxage = data["Age"].max()
    for i, row in data.iterrows():
        #x.append(extract_basic_features(row))
        #x.append(extract_gaze_type(row))
        x.append(extract_demographic(row, maxage))
    return x, y


def hist_complexity(data, hist=1):
    return


def regress(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
    regressor = LinearRegression()
    regressor.fit(x_train, y_train)
    y_pred = regressor.predict(x_test)
    r2 = sk.metrics.r2_score(y_test, y_pred)
    print("R2: ", r2)
    print("coefficients: ")
    print(regressor.coef_)
    return regressor


df = pd.read_csv("gaze_pattern.csv")
df = df[df["SwitchProportion"] != "Demo"]
df = df[df["GazePattern"] != "Other"]
x, y = setup_data(df)
regress(x, y)


# %%
# 1-depth inference
# i.e. consider transition probabilities between contexts

pp_s_given_c = np.array
pp_c_given_c0 = np.array

ax_c, ax_c0, ax_s, ax_s0 = 0, 1, 2, 3

pp_c0 = np.expand_dims(pp_c, axis=(ax_c, ax_s))
pp_s0_given_c0 = np.expand_dims(pp_s_given_c, axis=(ax_c, ax_s))
pp_c0_given_s0 = normalize(np.multiply(pp_s0_given_c0, pp_c0), axis=ax_c0)
pp_c_given_s0 = expectation(pp_c_given_c0, pp_c0_given_s0, axis=ax_c0)


ax_c, ax_x, ax_s, ax_s0 = 0, 1, 2, 3

pp_s_given_c_s0 = np.expand_dims(pp_s_given_c, axis=ax_s0)  # by conditional independence
pp_c_given_s_s0 = bayes(pp_s_given_c_s0, pp_c_given_s0)


